# -*- coding: utf-8 -*-
"""Naive_Bayes_Code_Gupo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zlfjj1LjUWaQj68wnlv5rBYzxJ7G98-K
"""

#opening file in your directory
my_file_handle=open("C://Users//Vincent//emails//normal//normal1.txt")
my_file_handle.read()

def listToString(first_line): 
    
    # initialize an empty string
    str1 = "" 
    
    # traverse in the string  
    for ele in first_line: 
        str1 += ele  
    
    # return string  
    return str1

#getting the normal email from the text file
num_of_file = 1
normal_subject = []
for i in range(10):
    a_file = open("C://Users//Vincent//emails//normal//normal"+ str(num_of_file) +".txt", "r")
    lines = a_file.readlines()
    first_line = lines[:1]
    string = listToString(first_line)
    num_of_file += 1
    normal_subject.append(string)

#Removing /n from the list and lowering all letters
normal = []
for element in normal_subject:
    normal.append(element.strip())

for i in range(len(normal)):
    normal[i] = normal[i].lower()

#print(normal)

#Removing special letters (:,-,?)
new_list = [s.replace(":", "") for s in normal]
new_list = [s.replace('"', "") for s in new_list]
new_list = [s.replace('?', "") for s in new_list]
new_list = [s.replace('-', "") for s in new_list]

#Splitting list of sentence into words
def convert(new_list):
    return ([i for item in new_list for i in item.split()])
      
new_list = (convert(new_list))

#Sort all the words alphabetically
normal_words = []
new_list.sort()
for word in new_list:
   normal_words.append(word)
#print(normal_words)

#convert the list in a dictionary with the occurence of the word as its value
normalword_freq = {i:normal_words.count(i) for i in normal_words}

#add 1 in all the occurences in case (pseudocounts)
for k in list(normalword_freq):
    normalword_freq[k] = normalword_freq.get(k, 0) + 1
    

#sum of words in normal
num_of_words =sum(normalword_freq.values())

#getting the probability of a word in a normal email
for k in list(normalword_freq):
    normalword_freq[k] =normalword_freq.get(k, 0)/num_of_words
#print(normalword_freq)

#getting the spam email from the text file
num_of_file = 1
spam_subject = []
for i in range(10):
    b_file = open("C://Users//Vincent//emails//spam//spam"+ str(num_of_file) +".txt", "r",encoding="utf8")
    lines = b_file.readlines()
    first_line = lines[:1]
    string = listToString(first_line)
    num_of_file += 1
    spam_subject.append(string)
        
#print(spam_subject)

#Removing /n from the list and lowering all letters
spam = []
for element in spam_subject:
    spam.append(element.strip())

for i in range(len(normal)):
    spam[i] = spam[i].lower()

#print(spam)

#Removing special letters (:,-,?)
new_list = [s.replace(":", "") for s in spam]
new_list = [s.replace('"', "") for s in new_list]
new_list = [s.replace('?', "") for s in new_list]
new_list = [s.replace('-', "") for s in new_list]

#Splitting list of sentence into words
def convert(new_list):
    return ([i for item in new_list for i in item.split()])

      
new_list = (convert(new_list))
#print(new_list)

#Sort all the words alphabetically
spam_words = []
new_list.sort()
for word in new_list:
   spam_words.append(word)
#print(spam_words)

#convert the list in a dictionary with the occurence of the word as its value
spamword_freq = {i:spam_words.count(i) for i in spam_words}
#print(spamword_freq)

#sum of words in spam
num_of_words =sum(spamword_freq.values())
#print(num_of_words)

#add 1 in all the occurences in case (pseudocounts)
for k in list(spamword_freq):
    spamword_freq[k] = spamword_freq.get(k, 0) + 1
#print(spamword_freq)


#getting the probability of a word in a spam email
for k in list(spamword_freq):
    spamword_freq[k] = spamword_freq.get(k, 0)/num_of_words
#print(spamword_freq)

#convert normal email key and value to list
keys_list_normal = list(normalword_freq)
values = normalword_freq.values()
values_list_normal = list(values)

#convert spam email key and value to list
keys_list_spam = list(spamword_freq)
values = spamword_freq.values()
values_list_spam = list(values)

#implementation of Naive Bayes algorithm
def NaiveBayes(user_input_split):
    freq_of_normal_email_in_training_set = 0.5
    freq_of_spam_email_in_training_set = 0.5
    prob_normal = freq_of_normal_email_in_training_set
    prob_spam = freq_of_spam_email_in_training_set
    index_normal = 0
    index_spam = 0
    
    #normal email
    for word in user_input_split:
        try:
            index_value = keys_list_normal.index(user_input_split[index_normal])
            prob_normal *= values_list_normal[index_value]
        except:
            prob_normal *= 0.008
        index_normal += 1
   
    
    #spam email
    for word in user_input_split:
        try:
            index_value = keys_list_spam.index(user_input_split[index_spam])
            prob_spam *= values_list_spam[index_value]
        except:
            prob_spam *= 0.008
        index_spam += 1
    
    
    if prob_normal > prob_spam:
        print("Normal ")
    if prob_normal < prob_spam:
        print("Spam")
    if prob_normal == prob_spam:
        print("I don't have a data to classify this email. Please check it yourself")

#splitting of the words that the user will input
def word_split(user_input):
    return (user_input[0].split())

#user input
user_input = input("Type the subject of your email here: ").lower()
user_input_split = user_input.split()
NaiveBayes(user_input_split)

